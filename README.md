#Debate on Deep Learning and Symbolic Reasoning

In this document, I discuss two articles about the same topic concerning deep learning and symbolic reasoning but holding different perspectives.

##Article 1

Yanb LeCun's [What AI Can Tell Us About Intelligence] (https://www.noemamag.com/what-ai-can-tell-us-about-intelligence/) in NOEMA dicusses the recent "wall", symbolic reasoning, that Deep Learning seems to encounter. LeCun states his disagreement on the idea, supported by scientist like Gary Marcus, that since symbolic reasoning needed to be explicited programmed from the begining, since the manipulations of symbols follow logical and algebraic principles, similar to how humans learn them.

However, LeCun points out that deep learning can perform symbolic reasoning; he believes that Marcus' approach, "distilling human expertise into rules and facts", is challenging and goes against the actual ambiguity of the real world. However, deep learning, particularly through neural networks, excels at handling ambiguity for it can learn and represent relationships between symbols and concepts by clustering similar data points. Therefore, a hybrid model that Marcus suggested is not the solution for the current strain in the development of deep learning, if there is a strain at all. 

##Article 2

In response, Gary Marcus states his opinion in [Deep Learning Alone Isnâ€™t Getting Us To Human-Like AI] (https://www.noemamag.com/deep-learning-alone-isnt-getting-us-to-human-like-ai/), also published in NEOMA, emphasizing his support on hybrid models that combine neural netwrok and symbol manipulation. Marcus points out that LeCun admitted the importance of symbolic manipulation for human-like AI and argues that a model is hybrid if the symbols are learned. 

Marcus further explains that a hybrid model is not simply combining a "hard-coded" symbolic manipulation model with a deep learning model: over years scientists have been studying various ways of building the proper hybrids. Moreover, Marcus questions the learnability of symbolic manipulation, stating that it is not guarantee that all systems are able to learn it. At the ends, Marcus concludes that deep learning has make progress but not so much fundamentally. When it comes to critical issue like symbolic-reasoning, pure deep learning may not suffice.
